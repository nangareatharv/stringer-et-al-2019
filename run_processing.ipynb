{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import glob\n",
    "%matplotlib inline\n",
    "from scipy.stats import zscore\n",
    "import importlib\n",
    "# modules\n",
    "import decoders, utils, tuning, learning, mainfigs, suppfigs\n",
    "\n",
    "### WHERE YOU DOWNLOADED THE FIGSHARE\n",
    "dataroot = \"C:/IITGn/Sem 2/Computation and Cognition/Project/8279387\"\n",
    "\n",
    "# file list\n",
    "# THIS WAS UPDATED ON NOV 5th!!! Please redownload + biased_V2 and static_sin_rand\n",
    "db = np.load(os.path.join(dataroot, 'database.npy'), allow_pickle=True)\n",
    "\n",
    "fs = []\n",
    "for di in db:\n",
    "    mname = di['mouse_name']\n",
    "    datexp = di['date']\n",
    "    blk = di['block']\n",
    "    stype = di['expt']\n",
    "    \n",
    "    fname = '%s_%s_%s_%s.npy'%(stype, mname, datexp, blk)\n",
    "    fs.append(os.path.join(dataroot, fname))\n",
    "\n",
    "### WHERE YOU WANT TO SAVE THE OUTPUTS OF THE ANALYSIS SCRIPTS AND THE FIGURES (if save_figure=True)\n",
    "saveroot = \"C:/IITGn/Sem 2/Computation and Cognition/Project/Output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>>>>>>>> independent <<<<<<<<<<<<<<\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 28\u001b[0m\n\u001b[0;32m     25\u001b[0m         np\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(saveroot,\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_decoder_asymp.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39mdstr[dtype]), \n\u001b[0;32m     26\u001b[0m                         {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE\u001b[39m\u001b[38;5;124m'\u001b[39m: E, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mccE\u001b[39m\u001b[38;5;124m'\u001b[39m: ccE, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnsplit\u001b[39m\u001b[38;5;124m'\u001b[39m: nsplit, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnpop\u001b[39m\u001b[38;5;124m'\u001b[39m: npop, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnstim\u001b[39m\u001b[38;5;124m'\u001b[39m: nstim, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE2\u001b[39m\u001b[38;5;124m'\u001b[39m: E2})\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 28\u001b[0m         E, ccE \u001b[38;5;241m=\u001b[39m \u001b[43mdecoders\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_independent_and_gain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m         np\u001b[38;5;241m.\u001b[39msave(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(saveroot,\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_decoder_and_gain.npy\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39mdstr[dtype]), \n\u001b[0;32m     30\u001b[0m                     {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mE\u001b[39m\u001b[38;5;124m'\u001b[39m: E, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mccE\u001b[39m\u001b[38;5;124m'\u001b[39m: ccE})\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m### decoding with subtracting spont\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nanga\\Documents\\GitHub\\stringer-et-al-2019\\decoders.py:779\u001b[0m, in \u001b[0;36mrun_independent_and_gain\u001b[1;34m(fs, npc)\u001b[0m\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t,f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(fs):\n\u001b[0;32m    777\u001b[0m     dat \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mload(f, allow_pickle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m--> 779\u001b[0m     sresp, istim, itrain, itest \u001b[38;5;241m=\u001b[39m \u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile_resp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnpc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnpc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    780\u001b[0m     ypos \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([dat[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstat\u001b[39m\u001b[38;5;124m'\u001b[39m][j][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmed\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(dat[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstat\u001b[39m\u001b[38;5;124m'\u001b[39m]))])\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# split neurons for decoder into strips (no Z overlap between two sets)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\nanga\\Documents\\GitHub\\stringer-et-al-2019\\utils.py:101\u001b[0m, in \u001b[0;36mcompile_resp\u001b[1;34m(dat, nskip, npc, zscore)\u001b[0m\n\u001b[0;32m     99\u001b[0m istim \u001b[38;5;241m=\u001b[39m dat[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mistim\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    100\u001b[0m \u001b[38;5;66;03m# split stims into test and train\u001b[39;00m\n\u001b[1;32m--> 101\u001b[0m itest \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((istim\u001b[38;5;241m.\u001b[39msize,), \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbool\u001b[49m)\n\u001b[0;32m    102\u001b[0m itest[::nskip] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    103\u001b[0m itrain \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((istim\u001b[38;5;241m.\u001b[39msize,), np\u001b[38;5;241m.\u001b[39mbool)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\numpy\\__init__.py:319\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(attr)\u001b[0m\n\u001b[0;32m    314\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    315\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn the future `np.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` will be defined as the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    316\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorresponding NumPy scalar.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;167;01mFutureWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;129;01min\u001b[39;00m __former_attrs__:\n\u001b[1;32m--> 319\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(__former_attrs__[attr])\n\u001b[0;32m    321\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attr \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtesting\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    322\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtesting\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'bool'.\n`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\nThe aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:\n    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations"
     ]
    }
   ],
   "source": [
    "#~~~~~~~~~~~~~~~ DATA ANALYSIS ~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "\n",
    "################### DECODING ANGLES 0-360 #######################\n",
    "dstr = ['independent', 'linear']\n",
    "for dtype in range(2):\n",
    "    print('>>>>>>>>>> %s <<<<<<<<<<<<<<'%dstr[dtype])\n",
    "    if dtype==0:\n",
    "        islinear=False\n",
    "    else:\n",
    "        islinear=True\n",
    "        \n",
    "    ### DECODER\n",
    "    nangles = 2 * np.pi * np.ones((len(fs)-5,))\n",
    "    nangles[-3:] = np.pi\n",
    "    if dtype==1:\n",
    "        E, errors, stims, SNR, theta_pref = decoders.run_decoder(fs[:-8], \n",
    "                                                             linear=islinear, \n",
    "                                                             nangles=nangles)\n",
    "        np.save(os.path.join(saveroot,'%s_decoder_all_stims.npy'%dstr[dtype]), \n",
    "                {'E': E, 'errors': errors, 'stims': stims})\n",
    "    \n",
    "        ### ASYMPTOTIC ANALYSIS\n",
    "        E, ccE, nsplit, npop, nstim, E2 = decoders.asymptotics(fs[:6], linear=islinear)\n",
    "        np.save(os.path.join(saveroot,'%s_decoder_asymp.npy'%dstr[dtype]), \n",
    "                        {'E': E, 'ccE': ccE, 'nsplit': nsplit, 'npop': npop, 'nstim': nstim, 'E2': E2})\n",
    "    else:\n",
    "        E, ccE = decoders.run_independent_and_gain(fs[:6])\n",
    "        np.save(os.path.join(saveroot,'%s_decoder_and_gain.npy'%dstr[dtype]), \n",
    "                    {'E': E, 'ccE': ccE})\n",
    "\n",
    "### decoding with subtracting spont\n",
    "E, errors, stims, SNR, theta_pref = decoders.run_decoder(fs[:-8], linear=islinear, npc=32)\n",
    "np.save(os.path.join(saveroot,'%s_decoder_without_spont.npy'%dstr[dtype]), \n",
    "                {'E': E, 'errors': errors, 'stims': stims})\n",
    "\n",
    "### linear decoding from PC's\n",
    "nPC = 2**np.arange(2,13,1)\n",
    "errors, apreds, atrues = decoders.pc_decoding(fs[:6], nPC)\n",
    "np.save(os.path.join(saveroot, 'pcdecode.npy'), \n",
    "        {'errors': errors, 'apreds': apreds, 'atrues': atrues, 'nPC': nPC})\n",
    "\n",
    "### linear decoding from dense recordings for information content\n",
    "Eneur, Estim, npop, nstim = decoders.dense_asymptotics(fs[-8:-3])\n",
    "np.save(os.path.join(saveroot, 'dense_decoding.npy'), \n",
    "        {'npop': npop, 'nstim': nstim, 'Eneur': Eneur, 'Estim': Estim})\n",
    "\n",
    "### linear decoding from dense recordings for information content from V2\n",
    "Eneur, Estim, npop, nstim = decoders.dense_asymptotics(fs[-3:])\n",
    "np.save(os.path.join(saveroot, 'dense_decoding_V2.npy'), \n",
    "        {'npop': npop, 'nstim': nstim, 'Eneur': Eneur, 'Estim': Estim})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### SINGLE NEURON STATS ########################\n",
    "\n",
    "# load a dataset for stim distances\n",
    "dat = np.load(fs[0], allow_pickle=True).item()\n",
    "sresp, istim, itrain, itest = utils.compile_resp(dat, npc=0)\n",
    "\n",
    "### STIMULUS DISTANCES\n",
    "cc, dtheta_aligned, cbinned, embedding = tuning.population_distances(sresp, istim)\n",
    "np.save(os.path.join(saveroot,'popdist.npy'), \n",
    "        {'cc':cc, 'dtheta_aligned': dtheta_aligned, 'cbinned':cbinned,'embedding':embedding, 'istim': istim})\n",
    "\n",
    "###### population tuning curves\n",
    "d = np.load(os.path.join(saveroot, 'independent_decoder_all_stims.npy'), allow_pickle=True).item()\n",
    "angle_pref = d['theta_pref']\n",
    "### static gratings population tuning curves\n",
    "avg_tuning, tbins = tuning.population_tuning(fs[:6], angle_pref[:6], saveroot)\n",
    "np.save(os.path.join(saveroot,'avgneur_static.npy'), \n",
    "        {'avg_tuning': avg_tuning, 'thetas': angle_pref[:6], 'tbins': tbins})\n",
    "\n",
    "### drifting gratings population tuning curves\n",
    "avg_tuning, tbins = tuning.population_tuning(fs[18:21], angle_pref[18:21], saveroot)\n",
    "np.save(os.path.join(saveroot,'avgneur_drifting.npy'), \n",
    "        {'avg_tuning': avg_tuning, 'thetas': angle_pref[18:21], 'tbins': tbins})\n",
    "    \n",
    "sigvar, twor_ex = tuning.signal_variance(fs[:6])    \n",
    "np.save(os.path.join(saveroot, 'twop_sigvar.npy'), {'sigvar': sigvar, 'twor_ex': A})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################ DISCRIMINATION TASK #######################\n",
    "print('DISCRIMINATION')\n",
    "\n",
    "### linear discriminator (all datasets except biased)\n",
    "nangles = 2 * np.pi * np.ones((len(fs)-5,))\n",
    "nangles[-3:] = np.pi\n",
    "P,d75,drange = decoders.run_discrimination(fs[:-8], nangles=nangles, decoder='linear')\n",
    "np.save(os.path.join(saveroot, 'linear_discrimination.npy'), \n",
    "        {'P': P, 'd75': d75, 'drange': drange})\n",
    "\n",
    "### linear discriminator on biased datasets (43-47 degree stimuli shown only)\n",
    "npop,nstim,Pall,drange = decoders.dense_discrimination(fs[-8:-3])\n",
    "np.save(os.path.join(saveroot, 'dense_discrimination.npy'), \n",
    "        {'npop': npop, 'nstim': nstim, 'Pall': Pall, 'drange': drange})\n",
    "\n",
    "### linear discriminator on biased datasets in V2 (43-47 degree stimuli shown only)\n",
    "npop,nstim,Pall,drange = decoders.dense_discrimination(fs[-3:])\n",
    "np.save(os.path.join(saveroot, 'dense_discrimination_V2.npy'), \n",
    "        {'npop': npop, 'nstim': nstim, 'Pall': Pall, 'drange': drange})\n",
    "\n",
    "###  discrimination in passive versus running trials\n",
    "all_running = np.load(os.path.join(dataroot, 'all_running.npy'), allow_pickle=True)\n",
    "P,d75,drange = decoders.runspeed_discrimination(fs[:6], all_running[:6])\n",
    "np.save(os.path.join(saveroot, 'runspeed_discrimination.npy'), {'P': P, 'd75': d75, 'drange': drange})\n",
    "\n",
    "### depth discrimination (split into layers 2/3 and layer 4)\n",
    "all_depths = np.load(os.path.join(dataroot, 'all_depths.npy'), allow_pickle=True)\n",
    "P,d75,drange = decoders.layer_discrimination(fs[:6], all_depths[:6])\n",
    "np.save(os.path.join(saveroot, 'layer_discrimination.npy'), {'P': P, 'd75': d75, 'drange': drange})\n",
    "\n",
    "### chron discrimination (split train/test in time)\n",
    "P,d75,drange = decoders.chron_discrimination(fs[:6], all_depths[:6])\n",
    "np.save(os.path.join(saveroot, 'chron_discrimination.npy'), {'P': P, 'd75': d75, 'drange': drange})\n",
    "\n",
    "### neural network discriminator\n",
    "P,d75,drange = decoders.run_discrimination(fs[:6], decoder='deep_net')\n",
    "np.save(os.path.join(saveroot, 'nn_discrimination.npy'), {'P': P, 'd75': d75, 'drange': drange})\n",
    "\n",
    "### random forest discriminator\n",
    "P,d75,drange = decoders.run_discrimination(fs[:6], decoder='random_forest')\n",
    "np.save(os.path.join(saveroot, 'rf_discrimination.npy'), {'P': P, 'd75': d75, 'drange': drange})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#~~~~~~~~~~~~~~~ PERCEPTRONS ~~~~~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "### PERCEPTRONS\n",
    "# train on easy task\n",
    "nstim32, perf32 = learning.train_perceptrons(fs[:6], task_type='easy')\n",
    "# train on hard task\n",
    "nstim, perf = learning.train_perceptrons(fs[-8:-3], task_type='hard')\n",
    "np.save(os.path.join(saveroot, 'strong_learn.npy'), \n",
    "         {'nstim32': nstim32, 'perf32': perf32, 'perf': perf, 'nstim': nstim})\n",
    "\n",
    "\n",
    "### WEAK LEARNERS\n",
    "# train on easy task\n",
    "P, drange, ccN = learning.train_weak_learners(fs[:6])\n",
    "np.save(os.path.join(saveroot, 'weak_learn.npy'), {'P': P, 'drange': drange, 'ccN': ccN})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InlineBackend.close_figures = False\n",
    "%config InlineBackend.print_figure_kwargs={'bbox_inches':None}\n",
    "\n",
    "imp.reload(mainfigs)\n",
    "imp.reload(suppfigs)\n",
    "\n",
    "#### MAIN FIGURES\n",
    "\n",
    "f = mainfigs.fig1(dataroot, saveroot, True)\n",
    "\n",
    "f = mainfigs.fig2(dataroot, saveroot, True)\n",
    "\n",
    "f = mainfigs.fig3(dataroot,saveroot, True)\n",
    "\n",
    "f = mainfigs.fig4(dataroot, saveroot, True)\n",
    "\n",
    "f = mainfigs.fig5(dataroot, saveroot, True)\n",
    "\n",
    "f = mainfigs.fig6(dataroot, saveroot, True)\n",
    "\n",
    "#### SUPPLEMENTARY FIGURES\n",
    "# if you want to save the figures, add an optional input save_figure=True\n",
    "\n",
    "\n",
    "f = suppfigs.stim_props(saveroot, True)\n",
    "\n",
    "f = suppfigs.pc_errors(dataroot, saveroot, True)\n",
    "\n",
    "f = suppfigs.linear_decoders(dataroot, saveroot, True)\n",
    "\n",
    "f = suppfigs.spont_sub(saveroot, True)\n",
    "\n",
    "f = suppfigs.discr_all(saveroot, True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
